{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KL散度同样衡量两个概率分布的差异性，其值越大，差异性越大"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$KL散度的定义如下：$<br/>\n",
    "$$\n",
    "D_{kl}(p || q) = \\sum_{x}{p(x)ln\\frac{p(x)}{q(x)}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$如对于如下的概率分布：$<br/>\n",
    "<img src=\"4.jpg\" alt=\"\" width=\"80%\" height=\"80%\" align=\"center\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$KL散度计算方式为：$<br/>\n",
    "$D_{kl}(p || q) = 0.7 * ln \\frac{0.7}{0.2} + 0.05 * ln \\frac{0.05}{0.4} + 0.15 * \\frac{0.15}{0.3} + 0.1 * \\frac{0.1}{0.1} = 0.79$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KL散度与交叉熵的关系：<br/>\n",
    "$D_{kl}(p||q) = \\sum_x{p(x)ln\\frac{p(x)}{q(x)}} = -\\sum_x{p(x)ln(q(x))} + \\sum_{x}{p(x)ln(p(x))}$<br/>\n",
    "可见，DL散度是交叉熵减去熵，当p(x)已知时，熵为常数，此时可直接用交叉熵而不用KL散度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
