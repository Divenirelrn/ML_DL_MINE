{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "数据降维目的是消除冗余特征，降低特征之间的相关性，使得数据更容易分析，更易理解"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "主成分分析（principal components analysis）是一种经典的数据降维算法，在数据压缩、噪声消除等方面有广泛应用"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PCA的思想是将现有的特征空间映射到一个新的特征空间，新的特征空间的维度小于原特征空间，从而达到降维的目的"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$设X是原样本集，Y是映射到新空间中的表达，则：Y = PX，其中P为空间转换矩阵\\\\（基向量矩阵，每一维为新的坐标下的基）$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$PCA的度量准则为方差最大化，即映射到新的特征空间中后数据的离散程度最大\\\\（在新的特征空间下，数据投影到所有维度的方差之和最大）$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$假设X = \\left[ \\begin{matrix} a_1 & a_2 & ... & a_m\\\\ b_1 & b_2 & ... & b_m \\end{matrix} \\right]，\\\\（X已经是中心化后的数据，中心化的目的是为了便于计算方差与协方差）\\\\则X的协方差矩阵为C = \\left[ \\begin{matrix} conv(\\pmb{a}, \\pmb{a}) & conv(\\pmb{a}, \\pmb{b})\\\\ conv(\\pmb{a}, \\pmb{b}) & conv(\\pmb{b}, \\pmb{b}) \\end{matrix} \\right] = \\left[ \\begin{matrix} var(\\pmb{a}) & conv(\\pmb{a}, \\pmb{b})\\\\ conv(\\pmb{a}, \\pmb{b}) & var(\\pmb{b}) \\end{matrix} \\right] = \\left[ \\begin{matrix} \\frac{1}{m}\\sum_{i=1}^{m}{a_i^2} & \\frac{1}{m}\\sum_{i=1}^{m}{a_ib_i}\\\\ \\frac{1}{m}\\sum_{i=1}^{m}{a_ib_i} & \\frac{1}{m}\\sum_{i=1}^{m}{b_i^2} \\end{matrix} \\right] = \\frac{1}{m}XX^T，其中\\pmb{a}=[a_1, a_2, ..., a_m],\\\\ \\pmb{b}=[b_1, b_2, ..., b_m]$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$则Y的协方差矩阵D = \\frac{1}{m}{YY^T} = \\frac{1}{m}(PX)(PX)^T=\\frac{1}{m}PXX^TP^T = P(\\frac{1}{m}XX^T)P^T \\\\ = PCP^T = P\\left[ \\begin{matrix} \\frac{1}{m}\\sum_{i=1}^{m}{a_i^2} & \\frac{1}{m}\\sum_{i=1}^{m}{a_ib_i}\\\\ \\frac{1}{m}\\sum_{i=1}^{m}{a_ib_i} & \\frac{1}{m}\\sum_{i=1}^{m}{b_i^2} \\end{matrix} \\right]P^T$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$则根据方差最大化，目标函数可以写为：$<br/>\n",
    "$$\n",
    " \\begin{cases}\n",
    " \\max_{P}tr(PCP^T)\\\\\n",
    " s.t. PP^T = I\n",
    " \\end{cases}\n",
    "$$\n",
    "$利用拉格朗日乘子法求解P:$<br/>\n",
    "$J(P) = tr(PCP^T) + \\lambda (I - PP^T)$<br/>\n",
    "$求解\\frac{\\partial J(P)}{\\partial P}：$<br/>\n",
    "$dtr(PCP^T) = tr(dPCP^T) = tr(CP^TDP), 则\\frac{\\partial tr(PCP^T)}{\\partial P} = PC^T$<br/>\n",
    "$tr(-dPP^T) = tr(-P^TdP), 则\\frac{\\partial -PP^T}{\\partial P} = -P$<br/>\n",
    "$令\\frac{\\partial J(P)}{\\partial P} = 0， 可得PC^T - \\lambda P = 0, 则CP^T - \\lambda P^T = 0, 则CP^T = \\lambda P^T$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$可以看出，最优解P^*就是C的特征向量组成的矩阵$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$PCA算法流程：$<br/>\n",
    "$输入：m个n维样本集X = (x_1, x_2, ..., x_m)，要降维到的维数k$<br/>\n",
    "$输出：降维后的样本集Y$<br/>\n",
    "$step1: 对X进行中心化：x_i = x_i - \\frac{1}{m}\\sum_{j=1}^{m}{x_j}, x=1,2,...,m$<br/>\n",
    "$step2: 计算样本的协方差矩阵C = \\frac{1}{m}XX^T$<br/>\n",
    "$step3: 求出协方差矩阵的特征值及对应的特征向量（特征值分解或SVD奇异值分解）$<br/>\n",
    "$step4: 将特征向量按照对应的特征值大小从上至下按行排列成矩阵，取前k行组成矩阵P$<br/>\n",
    "$step5: Y = PX即为降维后的数据$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$k值也可以不指定，而是用另一种方式自动获得，指定一个降维到的主成分比重t, 0<t<=1, \\\\假设n个特征值为\\lambda_1 >= \\lambda_2 >= ... >= \\lambda_n, 则k通过以下方式获得：$<br/>\n",
    "$$\n",
    "\\frac{\\sum_{i=1}^{k}{\\lambda_i}}{\\sum_{i=1}^{n}{\\lambda_i}} >= t\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
