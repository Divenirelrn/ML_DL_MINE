{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "relu(rectified linear function)激活函数的数学形式如下：\n",
    "$$\n",
    "f(x) =\n",
    " \\begin{cases}\n",
    " x, x>=0\\\\\n",
    " 0, x<0\n",
    " \\end{cases}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "导数形式如下：\n",
    "$$\n",
    "f(x) =\n",
    " \\begin{cases}\n",
    " 1, x>=0\\\\\n",
    " 0, x<0\n",
    " \\end{cases}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "优点：克服了梯度消失的问题，成为网络的标准化激活函数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "缺点：<br/>\n",
    "1)输出不以0为中心<br/>\n",
    "2)死亡神经元问题。<br/>\n",
    "$ 如下图所示，设w服从均值为0.1的正态分布，若学习率过大，则梯度过大，在反向传播时很可能改变w的分布，假设变为均值为-0.1的正态分布，\\\\ l-1层的输出非0即1，w_i大部分为负，因此a_{l1}的输入很可能是负数，此时a_{l1}的输出为0，在反向传播时，\\delta'(h)=0，因此w(w_{11},w_{12},w_{13},w_{14})无法得到更新，\\\\a_{l1}神经元死亡。w本epoch无法更新，下一个epoch，l-1的输出同样非0即1，而w没有发生变化，因此下一次激活值同样为0，a_{l1}神经元一直死亡$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"7.jpg\" alt=\"\" width=\"30%\" height=\"30%\" align=\"center\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
